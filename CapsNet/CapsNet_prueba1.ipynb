{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Concatenate, Lambda, Dense, Dropout, Activation, Flatten, LSTM, SpatialDropout2D, Conv2D, MaxPooling2D,\n",
    "    AveragePooling2D, GlobalAveragePooling2D, UpSampling2D, BatchNormalization, ReLU, Input\n",
    ")\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras import optimizers, regularizers, backend as K\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, accuracy_score, f1_score, recall_score, precision_score, classification_report,\n",
    "    cohen_kappa_score, hamming_loss, log_loss, zero_one_loss, matthews_corrcoef, roc_curve, auc\n",
    ")\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, label_binarize\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from time import time\n",
    "import time as tm\n",
    "import datetime\n",
    "from skimage.util.shape import view_as_blocks\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import ntpath\n",
    "import copy\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tfkan.layers import DenseKAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters and Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 1, 30)\n"
     ]
    }
   ],
   "source": [
    "################################################## 30 SRM FILTERS\n",
    "srm_weights = np.load('../SRM_Kernels.npy') \n",
    "biasSRM=np.ones(30)\n",
    "print (srm_weights.shape)\n",
    "################################################## TLU ACTIVATION FUNCTION\n",
    "T3 = 3;\n",
    "def Tanh3(x):\n",
    "    tanh3 = K.tanh(x)*T3\n",
    "    return tanh3\n",
    "##################################################\n",
    "def thtanh(x,t):\n",
    "    th=K.tanh(x)*t\n",
    "    return th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S-UNIWARD BOSSbase 1.01 PAYLOAD = 0.4bpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 256, 256, 1)\n",
      "(12000, 2)\n",
      "(4000, 256, 256, 1)\n",
      "(4000, 2)\n",
      "(6000, 256, 256, 1)\n",
      "(4000, 2)\n"
     ]
    }
   ],
   "source": [
    "#Train\n",
    "X_train = np.load('../data_gbras/X_train.npy')\n",
    "y_train = np.load('../data_gbras/y_train.npy')\n",
    "#Valid\n",
    "X_valid = np.load('../data_gbras/X_valid.npy')\n",
    "y_valid = np.load('../data_gbras/y_valid.npy')\n",
    "#Test\n",
    "X_test = np.load('../data_gbras/X_test.npy')\n",
    "y_test = np.load('../data_gbras/y_test.npy')\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions arquitecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze_excitation_layer(input_layer, out_dim, ratio, conv):\n",
    "  squeeze = tf.keras.layers.GlobalAveragePooling2D()(input_layer)\n",
    "  excitation = tf.keras.layers.Dense(units=out_dim / ratio, activation='relu')(squeeze)\n",
    "  excitation = tf.keras.layers.Dense(out_dim,activation='sigmoid')(excitation)\n",
    "  excitation = tf.reshape(excitation, [-1,1,1,out_dim])\n",
    "  scale = tf.keras.layers.multiply([input_layer, excitation])\n",
    "  if conv:\n",
    "    shortcut = tf.keras.layers.Conv2D(out_dim,kernel_size=1,strides=1,\n",
    "                                      padding='same',kernel_initializer='he_normal')(input_layer)\n",
    "    shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
    "  else:\n",
    "    shortcut = input_layer\n",
    "  out = tf.keras.layers.add([shortcut, scale])\n",
    "  return out\n",
    "\n",
    "\n",
    "\n",
    "def sreLu (input):\n",
    "  return ReLU(negative_slope=0.1, threshold=0)(input)\n",
    "\n",
    "def sConv(input,parameters,size,nstrides):\n",
    "  return Conv2D(parameters, (size,size), strides=(nstrides,nstrides),padding=\"same\", kernel_initializer='glorot_normal', kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(input)\n",
    "\n",
    "def sBN (input):\n",
    "  return tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=True, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(input)\n",
    "\n",
    "def sGlobal_Avg_Pooling (input):\n",
    "  return tf.keras.layers.GlobalAveragePooling2D()(input)\n",
    "\n",
    "def sDense (input, n_units, activate_c):\n",
    "  return tf.keras.layers.Dense(n_units,activation=activate_c)(input)\n",
    "\n",
    "def smultiply (input_1, input_2):\n",
    "  return tf.keras.layers.multiply([input_1, input_2])\n",
    "\n",
    "def sadd (input_1, input_2):\n",
    "  return tf.keras.layers.add([input_1, input_2])\n",
    "\n",
    "# Initial learning rate for the optimizer\n",
    "initial_learning_rate = 0.001\n",
    "\n",
    "# Learning rate schedule with exponential decay\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Block_1 (input, parameter):\n",
    "  output = sConv(input, parameter, 3, 1)\n",
    "  output = sBN(output)\n",
    "  output = sreLu(output)\n",
    "  return output\n",
    "  \n",
    "\n",
    "\n",
    "def SE_Block(input, out_dim, ratio):\n",
    "  output = sGlobal_Avg_Pooling(input)\n",
    "  output = sDense(output, out_dim/ratio, 'relu')\n",
    "  output = sDense(output, out_dim, 'sigmoid')\n",
    "  return output\n",
    "  \n",
    "  \n",
    "  \n",
    "def Block_2 (input, parameter):\n",
    "  output = Block_1(input, parameter)\n",
    "  output = sConv(output, parameter, 3, 1)\n",
    "  output = sBN(output)\n",
    "  multiplier = SE_Block(output,  parameter, parameter)\n",
    "  # output = smultiply(output, output)\n",
    "  output = smultiply(multiplier, output)\n",
    "  output = sadd(output, input)\n",
    "  return output\n",
    "  \n",
    "  \n",
    "\n",
    "def Block_3 (input, parameter):\n",
    "  addition = sConv(input, parameter, 1, 2)\n",
    "  addition = sBN(addition)\n",
    "  output = sConv(input, parameter, 3, 2)\n",
    "  output = sBN(output)\n",
    "  output = sreLu(output)\n",
    "  output = sConv(output, parameter, 3, 1)\n",
    "  output = sBN(output)\n",
    "  multiplier = SE_Block(output,  parameter, parameter)\n",
    "  output = smultiply(multiplier, output)\n",
    "  output = sadd(output, addition)\n",
    "  return output  \n",
    "  \n",
    "def Block_4 (input, parameter):\n",
    "  output = Block_1(input, parameter)\n",
    "  output = sConv(input, parameter, 3, 1)\n",
    "  output = sBN(output)\n",
    "  \n",
    "  return output  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CapsNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clases=5\n",
    "vec=16\n",
    "class Capsnet(Layer):\n",
    "    # creating a layer class in keras\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Capsnet, self).__init__(**kwargs)\n",
    "        self.kernel_initializer = tf.keras.initializers.get('glorot_uniform')\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # initialize weight matrix for each capsule in lower layer\n",
    "        self.W = self.add_weight(shape = [1,1,num_clases, vec, 512], initializer = self.kernel_initializer, name = 'weights')\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        u = tf.reshape(inputs, (-1, 1, 512)) # u.shape: (None, 1152, 8)\n",
    "        u = tf.expand_dims(u, axis=-2) # u.shape: (None, 1152, 1, 8)\n",
    "        u = tf.expand_dims(u, axis=-1) # u.shape: (None, 1152, 1, 8, 1)\n",
    "        u_hat = tf.matmul(self.W, u) # u_hat.shape: (None, 1152, 10, 16, 1)\n",
    "        u_hat = tf.squeeze(u_hat, [4]) # u_hat.shape: (None, 1152, 10, 16)\n",
    "        b = tf.zeros(shape = [K.shape(inputs)[0],2, num_clases, 1])\n",
    "\n",
    "# routing algorithm with updating coupling coefficient c, using scalar product b/w input capsule and output capsule\n",
    "        for i in range(3-1):\n",
    "            c = tf.nn.softmax(b, axis=-2) # c.shape: (None, 1152, 10, 1)\n",
    "            s = tf.reduce_sum(tf.multiply(c, u_hat), axis=1, keepdims=True) # s.shape: (None, 1, 10, 16)\n",
    "            v = squash(s) # v.shape: (None, 1, 10, 16)\n",
    "            agreement = tf.squeeze(tf.matmul(tf.expand_dims(u_hat, axis=-1), tf.expand_dims(v, axis=-1), transpose_a=True), [4]) # agreement.shape: (None, 1152, 10, 1)\n",
    "            # Before matmul following intermediate shapes are present, they are not assigned to a variable but just for understanding the code.\n",
    "            # u_hat.shape (Intermediate shape) : (None, 1152, 10, 16, 1)\n",
    "            # v.shape (Intermediate shape): (None, 1, 10, 16, 1)\n",
    "            # Since the first parameter of matmul is to be transposed its shape becomes:(None, 1152, 10, 1, 16)\n",
    "            # Now matmul is performed in the last two dimensions, and others are broadcasted\n",
    "            # Before squeezing we have an intermediate shape of (None, 1152, 10, 1, 1)\n",
    "            b += agreement\n",
    "\n",
    "        return v\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tuple([None, num_clases, vec])\n",
    "\n",
    "epsilon = 1e-7\n",
    "\n",
    "def output_layer(inputs):\n",
    "    return K.sqrt(K.sum(K.square(inputs), -1) + K.epsilon())\n",
    "\n",
    "def squash(inputs):\n",
    "    # take norm of input vectors\n",
    "    squared_norm = tf.keras.backend.sum(tf.keras.backend.square(inputs), axis = -1, keepdims = True)\n",
    "\n",
    "    # use the formula for non-linear function to return squashed output\n",
    "    return ((squared_norm/(1+squared_norm))/(K.sqrt(squared_norm+K.epsilon())))*inputs\n",
    "\n",
    "def safe_norm(v, axis=-1, epsilon=1e-7):\n",
    "    v_ = tf.reduce_sum(tf.square(v), axis = axis, keepdims=True)\n",
    "    return tf.sqrt(v_ + epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, X_train, y_train, X_valid, y_valid, X_test, y_test, batch_size, epochs, initial_epoch = 0, model_name=\"\", num_test=\"\"):\n",
    "    start_time = tm.time()\n",
    "    log_dir=\"D:/testing_\"+num_test+\"/\"+model_name+\"_\"+\"{}\".format(time())\n",
    "    tensorboard = tf.keras.callbacks.TensorBoard(log_dir)\n",
    "    filepath = log_dir+\"/saved-model.hdf5\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath, \n",
    "        monitor='val_accuracy', \n",
    "        save_best_only=True, \n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "    model.reset_states()\n",
    "    history=model.fit(X_train, y_train, epochs=epochs, \n",
    "                        callbacks=[tensorboard,  checkpoint], \n",
    "                        batch_size=batch_size,\n",
    "                        validation_data=(X_valid, y_valid),\n",
    "                        initial_epoch=initial_epoch)\n",
    "    \n",
    "    metrics = model.evaluate(X_test, y_test, verbose=0)\n",
    "    results_dir=\"D:/testing_\"+num_test+\"/\"+model_name+\"/\"\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "      \n",
    "        plt.figure(figsize=(10, 10))\n",
    "        #plt.subplot(1,2,1)\n",
    "        #Plot training & validation accuracy values\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('Accuracy Vs Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "        plt.grid('on')\n",
    "        plt.savefig(results_dir+'Accuracy_Xu_Net_'+model_name+'.eps', format='eps')\n",
    "        plt.savefig(results_dir+'Accuracy_Xu_Net_'+model_name+'.svg', format='svg')\n",
    "        plt.savefig(results_dir+'Accuracy_Xu_Net_'+model_name+'.pdf', format='pdf')\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(10, 10))\n",
    "        #plt.subplot(1,2,2)\n",
    "        #Plot training & validation loss values\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('Loss Vs Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "        plt.grid('on')\n",
    "        plt.savefig(results_dir+'Loss_Xu_Net_'+model_name+'.eps', format='eps')\n",
    "        plt.savefig(results_dir+'Loss_Xu_Net_'+model_name+'.svg', format='svg')\n",
    "        plt.savefig(results_dir+'Loss_Xu_Net_'+model_name+'.pdf', format='pdf')\n",
    "        plt.show()\n",
    "\n",
    "    TIME = tm.time() - start_time\n",
    "    print(\"Time \"+model_name+\" = %s [seconds]\" % TIME)\n",
    "    return {k:v for k,v in zip (model.metrics_names, metrics)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvCapsNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output last layer before transformer (None, 16, 16, 512)\n",
      "(None, 16, 16, 512)\n",
      "Transformer_create\n"
     ]
    }
   ],
   "source": [
    "def new_arch():\n",
    "  tf.keras.backend.clear_session()\n",
    "  inputs = tf.keras.Input(shape=(256,256,1), name=\"input_1\")\n",
    "  #Layer 1\n",
    "  layers_ty = tf.keras.layers.Conv2D(30, (5,5), weights=[srm_weights,biasSRM], strides=(1,1), padding='same', trainable=False, activation=Tanh3, use_bias=True)(inputs)\n",
    "  layers_tn = tf.keras.layers.Conv2D(30, (5,5), weights=[srm_weights,biasSRM], strides=(1,1), padding='same', trainable=True, activation=Tanh3, use_bias=True)(inputs)\n",
    "\n",
    "  layers = tf.keras.layers.add([layers_ty, layers_tn])\n",
    "  layers1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "  #Layer 2\n",
    "  \n",
    "  # L1\n",
    "  layers = Block_1(layers1,64)\n",
    "\n",
    "  # L2\n",
    "  layers = Block_1(layers,64)\n",
    "\n",
    "  # L3 - L7\n",
    "  for i in range(5):\n",
    "    layers = Block_2(layers,64)\n",
    "\n",
    "  # L8 - L11\n",
    "  for i in [64, 64, 128, 256]:\n",
    "    layers = Block_3(layers,i)\n",
    "\n",
    "  # L12\n",
    "  layers = Block_4(layers,512)\n",
    "  print('output last layer before transformer', layers.shape)\n",
    "\n",
    "  Pool_1=tf.keras.layers.MaxPool1D(2)(layers)\n",
    "  #---------------------------------------------------Fin de Convolutional stage 2------------------------------------------------------------------------#\n",
    "  # Classify outputs.\n",
    "      #CAPSNET\n",
    "  squashed_output = tf.keras.layers.Lambda(squash)(Pool_1)\n",
    "  representation = Capsnet()(squashed_output)\n",
    "  representation = tf.keras.layers.GlobalAvgPool1D()(representation)\n",
    "  #Acont= safe_norm(representation)\n",
    "  #mast = tf.reshape(Acont, (-1,Acont.shape[2],Acont.shape[3]))\n",
    "  #predictions = tf.keras.layers.Lambda(output_layer)(mast)\n",
    "\n",
    "      #FC\n",
    "  layers = Dense(128,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(representation)\n",
    "  layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
    "  layers = Dense(64,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
    "  layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
    "  layers = Dense(32,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
    "  layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
    "\n",
    "  predictions = Dense(2, activation=\"softmax\", name=\"output_1\",kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
    "  model =tf.keras.Model(inputs = inputs, outputs=predictions)\n",
    " \n",
    "\n",
    "  model =tf.keras.Model(inputs = inputs, outputs=predictions)\n",
    " \n",
    "  # Compile the model if the compile flag is set\n",
    "\n",
    "  optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.95)\n",
    "  if compile:\n",
    "      model.compile(optimizer= optimizer,\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "      \n",
    "      print (\"ConvCapsNet create\")\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "model = new_arch()  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.9567 - accuracy: 0.4864\n",
      "Epoch 1: val_accuracy improved from -inf to 0.50225, saving model to D:/testing_1_cvt/Model_CVT_prueba1_04S-UNIWARD_1729515488.1369982\\saved-model.hdf5\n",
      "1500/1500 [==============================] - 719s 471ms/step - loss: 0.9567 - accuracy: 0.4864 - val_loss: 0.9519 - val_accuracy: 0.5023\n",
      "Epoch 2/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.9508 - accuracy: 0.4990\n",
      "Epoch 2: val_accuracy improved from 0.50225 to 0.53375, saving model to D:/testing_1_cvt/Model_CVT_prueba1_04S-UNIWARD_1729515488.1369982\\saved-model.hdf5\n",
      "1500/1500 [==============================] - 725s 483ms/step - loss: 0.9508 - accuracy: 0.4990 - val_loss: 0.9438 - val_accuracy: 0.5337\n",
      "Epoch 3/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.9437 - accuracy: 0.5309\n",
      "Epoch 3: val_accuracy improved from 0.53375 to 0.55350, saving model to D:/testing_1_cvt/Model_CVT_prueba1_04S-UNIWARD_1729515488.1369982\\saved-model.hdf5\n",
      "1500/1500 [==============================] - 728s 485ms/step - loss: 0.9437 - accuracy: 0.5309 - val_loss: 0.9344 - val_accuracy: 0.5535\n",
      "Epoch 4/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.9332 - accuracy: 0.5458\n",
      "Epoch 4: val_accuracy improved from 0.55350 to 0.63100, saving model to D:/testing_1_cvt/Model_CVT_prueba1_04S-UNIWARD_1729515488.1369982\\saved-model.hdf5\n",
      "1500/1500 [==============================] - 728s 486ms/step - loss: 0.9332 - accuracy: 0.5458 - val_loss: 0.8824 - val_accuracy: 0.6310\n",
      "Epoch 5/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.9192 - accuracy: 0.5634\n",
      "Epoch 5: val_accuracy improved from 0.63100 to 0.66850, saving model to D:/testing_1_cvt/Model_CVT_prueba1_04S-UNIWARD_1729515488.1369982\\saved-model.hdf5\n",
      "1500/1500 [==============================] - 727s 485ms/step - loss: 0.9192 - accuracy: 0.5634 - val_loss: 0.8367 - val_accuracy: 0.6685\n",
      "Epoch 6/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.9045 - accuracy: 0.5885\n",
      "Epoch 6: val_accuracy improved from 0.66850 to 0.67175, saving model to D:/testing_1_cvt/Model_CVT_prueba1_04S-UNIWARD_1729515488.1369982\\saved-model.hdf5\n",
      "1500/1500 [==============================] - 732s 488ms/step - loss: 0.9045 - accuracy: 0.5885 - val_loss: 0.8318 - val_accuracy: 0.6718\n",
      "Epoch 7/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.8882 - accuracy: 0.5980\n",
      "Epoch 7: val_accuracy improved from 0.67175 to 0.70350, saving model to D:/testing_1_cvt/Model_CVT_prueba1_04S-UNIWARD_1729515488.1369982\\saved-model.hdf5\n",
      "1500/1500 [==============================] - 732s 488ms/step - loss: 0.8882 - accuracy: 0.5980 - val_loss: 0.7703 - val_accuracy: 0.7035\n",
      "Epoch 8/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.8762 - accuracy: 0.6071\n",
      "Epoch 8: val_accuracy did not improve from 0.70350\n",
      "1500/1500 [==============================] - 746s 497ms/step - loss: 0.8762 - accuracy: 0.6071 - val_loss: 0.7814 - val_accuracy: 0.6930\n",
      "Epoch 9/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.8621 - accuracy: 0.6203\n",
      "Epoch 9: val_accuracy did not improve from 0.70350\n",
      "1500/1500 [==============================] - 733s 488ms/step - loss: 0.8621 - accuracy: 0.6203 - val_loss: 0.7741 - val_accuracy: 0.6995\n",
      "Epoch 10/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.8524 - accuracy: 0.6285\n",
      "Epoch 10: val_accuracy did not improve from 0.70350\n",
      "1500/1500 [==============================] - 733s 489ms/step - loss: 0.8524 - accuracy: 0.6285 - val_loss: 0.7664 - val_accuracy: 0.6980\n",
      "Epoch 11/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.8390 - accuracy: 0.6296\n",
      "Epoch 11: val_accuracy did not improve from 0.70350\n",
      "1500/1500 [==============================] - 732s 488ms/step - loss: 0.8390 - accuracy: 0.6296 - val_loss: 0.7767 - val_accuracy: 0.6902\n",
      "Epoch 12/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.8359 - accuracy: 0.6398\n",
      "Epoch 12: val_accuracy did not improve from 0.70350\n",
      "1500/1500 [==============================] - 730s 487ms/step - loss: 0.8359 - accuracy: 0.6398 - val_loss: 0.7615 - val_accuracy: 0.7020\n",
      "Epoch 13/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.8291 - accuracy: 0.6423\n",
      "Epoch 13: val_accuracy improved from 0.70350 to 0.71125, saving model to D:/testing_1_cvt/Model_CVT_prueba1_04S-UNIWARD_1729515488.1369982\\saved-model.hdf5\n",
      "1500/1500 [==============================] - 730s 487ms/step - loss: 0.8291 - accuracy: 0.6423 - val_loss: 0.7526 - val_accuracy: 0.7113\n",
      "Epoch 14/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.8117 - accuracy: 0.6506\n",
      "Epoch 14: val_accuracy improved from 0.71125 to 0.75000, saving model to D:/testing_1_cvt/Model_CVT_prueba1_04S-UNIWARD_1729515488.1369982\\saved-model.hdf5\n",
      "1500/1500 [==============================] - 731s 487ms/step - loss: 0.8117 - accuracy: 0.6506 - val_loss: 0.6696 - val_accuracy: 0.7500\n",
      "Epoch 15/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.8033 - accuracy: 0.6561\n",
      "Epoch 15: val_accuracy did not improve from 0.75000\n",
      "1500/1500 [==============================] - 745s 496ms/step - loss: 0.8033 - accuracy: 0.6561 - val_loss: 0.7872 - val_accuracy: 0.7290\n",
      "Epoch 16/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.8005 - accuracy: 0.6603\n",
      "Epoch 16: val_accuracy did not improve from 0.75000\n",
      "1500/1500 [==============================] - 733s 489ms/step - loss: 0.8005 - accuracy: 0.6603 - val_loss: 0.7240 - val_accuracy: 0.7212\n",
      "Epoch 17/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.7895 - accuracy: 0.6629\n",
      "Epoch 17: val_accuracy did not improve from 0.75000\n",
      "1500/1500 [==============================] - 733s 489ms/step - loss: 0.7895 - accuracy: 0.6629 - val_loss: 0.7291 - val_accuracy: 0.7225\n",
      "Epoch 18/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.7788 - accuracy: 0.6664\n",
      "Epoch 18: val_accuracy did not improve from 0.75000\n",
      "1500/1500 [==============================] - 734s 490ms/step - loss: 0.7788 - accuracy: 0.6664 - val_loss: 0.7096 - val_accuracy: 0.7230\n",
      "Epoch 19/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.7748 - accuracy: 0.6744\n",
      "Epoch 19: val_accuracy did not improve from 0.75000\n",
      "1500/1500 [==============================] - 732s 488ms/step - loss: 0.7748 - accuracy: 0.6744 - val_loss: 0.6625 - val_accuracy: 0.7498\n",
      "Epoch 20/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.7604 - accuracy: 0.6818\n",
      "Epoch 20: val_accuracy did not improve from 0.75000\n",
      "1500/1500 [==============================] - 735s 490ms/step - loss: 0.7604 - accuracy: 0.6818 - val_loss: 0.7019 - val_accuracy: 0.7335\n",
      "Epoch 21/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.7570 - accuracy: 0.6772\n",
      "Epoch 21: val_accuracy did not improve from 0.75000\n",
      "1500/1500 [==============================] - 732s 488ms/step - loss: 0.7570 - accuracy: 0.6772 - val_loss: 0.6745 - val_accuracy: 0.7330\n",
      "Epoch 22/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.7475 - accuracy: 0.6809\n",
      "Epoch 22: val_accuracy did not improve from 0.75000\n",
      "1500/1500 [==============================] - 729s 486ms/step - loss: 0.7475 - accuracy: 0.6809 - val_loss: 0.7112 - val_accuracy: 0.7168\n",
      "Epoch 23/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.7391 - accuracy: 0.6957\n",
      "Epoch 23: val_accuracy improved from 0.75000 to 0.76700, saving model to D:/testing_1_cvt/Model_CVT_prueba1_04S-UNIWARD_1729515488.1369982\\saved-model.hdf5\n",
      "1500/1500 [==============================] - 742s 495ms/step - loss: 0.7391 - accuracy: 0.6957 - val_loss: 0.6568 - val_accuracy: 0.7670\n",
      "Epoch 24/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.7357 - accuracy: 0.6938\n",
      "Epoch 24: val_accuracy did not improve from 0.76700\n",
      "1500/1500 [==============================] - 730s 487ms/step - loss: 0.7357 - accuracy: 0.6938 - val_loss: 0.7120 - val_accuracy: 0.7437\n",
      "Epoch 25/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.7272 - accuracy: 0.6973\n",
      "Epoch 25: val_accuracy did not improve from 0.76700\n",
      "1500/1500 [==============================] - 733s 489ms/step - loss: 0.7272 - accuracy: 0.6973 - val_loss: 0.7198 - val_accuracy: 0.7477\n",
      "Epoch 26/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.7191 - accuracy: 0.6992\n",
      "Epoch 26: val_accuracy did not improve from 0.76700\n",
      "1500/1500 [==============================] - 734s 490ms/step - loss: 0.7191 - accuracy: 0.6992 - val_loss: 0.6966 - val_accuracy: 0.7570\n",
      "Epoch 27/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.7086 - accuracy: 0.7078\n",
      "Epoch 27: val_accuracy did not improve from 0.76700\n",
      "1500/1500 [==============================] - 737s 491ms/step - loss: 0.7086 - accuracy: 0.7078 - val_loss: 0.6937 - val_accuracy: 0.7433\n",
      "Epoch 28/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.7073 - accuracy: 0.7080\n",
      "Epoch 28: val_accuracy did not improve from 0.76700\n",
      "1500/1500 [==============================] - 736s 490ms/step - loss: 0.7073 - accuracy: 0.7080 - val_loss: 0.7187 - val_accuracy: 0.7495\n",
      "Epoch 29/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.6917 - accuracy: 0.7164\n",
      "Epoch 29: val_accuracy improved from 0.76700 to 0.77075, saving model to D:/testing_1_cvt/Model_CVT_prueba1_04S-UNIWARD_1729515488.1369982\\saved-model.hdf5\n",
      "1500/1500 [==============================] - 735s 490ms/step - loss: 0.6917 - accuracy: 0.7164 - val_loss: 0.6557 - val_accuracy: 0.7707\n",
      "Epoch 30/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.6901 - accuracy: 0.7167\n",
      "Epoch 30: val_accuracy did not improve from 0.77075\n",
      "1500/1500 [==============================] - 736s 491ms/step - loss: 0.6901 - accuracy: 0.7167 - val_loss: 0.6293 - val_accuracy: 0.7685\n",
      "Epoch 31/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.6797 - accuracy: 0.7225\n",
      "Epoch 31: val_accuracy improved from 0.77075 to 0.78625, saving model to D:/testing_1_cvt/Model_CVT_prueba1_04S-UNIWARD_1729515488.1369982\\saved-model.hdf5\n",
      "1500/1500 [==============================] - 749s 499ms/step - loss: 0.6797 - accuracy: 0.7225 - val_loss: 0.6509 - val_accuracy: 0.7862\n",
      "Epoch 32/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.6764 - accuracy: 0.7243\n",
      "Epoch 32: val_accuracy did not improve from 0.78625\n",
      "1500/1500 [==============================] - 727s 484ms/step - loss: 0.6764 - accuracy: 0.7243 - val_loss: 0.7232 - val_accuracy: 0.7475\n",
      "Epoch 33/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.6703 - accuracy: 0.7330\n",
      "Epoch 33: val_accuracy did not improve from 0.78625\n",
      "1500/1500 [==============================] - 726s 484ms/step - loss: 0.6703 - accuracy: 0.7330 - val_loss: 0.6426 - val_accuracy: 0.7540\n",
      "Epoch 34/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.6615 - accuracy: 0.7322\n",
      "Epoch 34: val_accuracy did not improve from 0.78625\n",
      "1500/1500 [==============================] - 727s 484ms/step - loss: 0.6615 - accuracy: 0.7322 - val_loss: 0.6363 - val_accuracy: 0.7697\n",
      "Epoch 35/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.6571 - accuracy: 0.7371\n",
      "Epoch 35: val_accuracy did not improve from 0.78625\n",
      "1500/1500 [==============================] - 729s 486ms/step - loss: 0.6571 - accuracy: 0.7371 - val_loss: 0.6141 - val_accuracy: 0.7807\n",
      "Epoch 36/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.6531 - accuracy: 0.7397\n",
      "Epoch 36: val_accuracy did not improve from 0.78625\n",
      "1500/1500 [==============================] - 732s 488ms/step - loss: 0.6531 - accuracy: 0.7397 - val_loss: 0.7280 - val_accuracy: 0.7513\n",
      "Epoch 37/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.6436 - accuracy: 0.7441\n",
      "Epoch 37: val_accuracy improved from 0.78625 to 0.79650, saving model to D:/testing_1_cvt/Model_CVT_prueba1_04S-UNIWARD_1729515488.1369982\\saved-model.hdf5\n",
      "1500/1500 [==============================] - 733s 489ms/step - loss: 0.6436 - accuracy: 0.7441 - val_loss: 0.5980 - val_accuracy: 0.7965\n",
      "Epoch 38/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.6336 - accuracy: 0.7498\n",
      "Epoch 38: val_accuracy did not improve from 0.79650\n",
      "1500/1500 [==============================] - 732s 488ms/step - loss: 0.6336 - accuracy: 0.7498 - val_loss: 0.5873 - val_accuracy: 0.7878\n",
      "Epoch 39/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.6254 - accuracy: 0.7552\n",
      "Epoch 39: val_accuracy did not improve from 0.79650\n",
      "1500/1500 [==============================] - 745s 497ms/step - loss: 0.6254 - accuracy: 0.7552 - val_loss: 0.7391 - val_accuracy: 0.7640\n",
      "Epoch 40/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.6238 - accuracy: 0.7553\n",
      "Epoch 40: val_accuracy did not improve from 0.79650\n",
      "1500/1500 [==============================] - 735s 490ms/step - loss: 0.6238 - accuracy: 0.7553 - val_loss: 0.6414 - val_accuracy: 0.7617\n",
      "Epoch 41/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.6093 - accuracy: 0.7617\n",
      "Epoch 41: val_accuracy improved from 0.79650 to 0.80475, saving model to D:/testing_1_cvt/Model_CVT_prueba1_04S-UNIWARD_1729515488.1369982\\saved-model.hdf5\n",
      "1500/1500 [==============================] - 735s 490ms/step - loss: 0.6093 - accuracy: 0.7617 - val_loss: 0.5609 - val_accuracy: 0.8048\n",
      "Epoch 42/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.6065 - accuracy: 0.7642\n",
      "Epoch 42: val_accuracy did not improve from 0.80475\n",
      "1500/1500 [==============================] - 732s 488ms/step - loss: 0.6065 - accuracy: 0.7642 - val_loss: 0.5898 - val_accuracy: 0.7995\n",
      "Epoch 43/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.6023 - accuracy: 0.7655\n",
      "Epoch 43: val_accuracy did not improve from 0.80475\n",
      "1500/1500 [==============================] - 729s 486ms/step - loss: 0.6023 - accuracy: 0.7655 - val_loss: 0.6141 - val_accuracy: 0.7958\n",
      "Epoch 44/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.5971 - accuracy: 0.7686\n",
      "Epoch 44: val_accuracy did not improve from 0.80475\n",
      "1500/1500 [==============================] - 732s 488ms/step - loss: 0.5971 - accuracy: 0.7686 - val_loss: 0.7490 - val_accuracy: 0.7778\n",
      "Epoch 45/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.5881 - accuracy: 0.7746\n",
      "Epoch 45: val_accuracy did not improve from 0.80475\n",
      "1500/1500 [==============================] - 738s 492ms/step - loss: 0.5881 - accuracy: 0.7746 - val_loss: 0.6979 - val_accuracy: 0.7845\n",
      "Epoch 46/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.5833 - accuracy: 0.7736\n",
      "Epoch 46: val_accuracy did not improve from 0.80475\n",
      "1500/1500 [==============================] - 746s 498ms/step - loss: 0.5833 - accuracy: 0.7736 - val_loss: 0.6287 - val_accuracy: 0.7815\n",
      "Epoch 47/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.5843 - accuracy: 0.7747\n",
      "Epoch 47: val_accuracy did not improve from 0.80475\n",
      "1500/1500 [==============================] - 763s 509ms/step - loss: 0.5843 - accuracy: 0.7747 - val_loss: 0.5917 - val_accuracy: 0.7843\n",
      "Epoch 48/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.5687 - accuracy: 0.7841\n",
      "Epoch 48: val_accuracy did not improve from 0.80475\n",
      "1500/1500 [==============================] - 751s 501ms/step - loss: 0.5687 - accuracy: 0.7841 - val_loss: 0.6671 - val_accuracy: 0.7952\n",
      "Epoch 49/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.5712 - accuracy: 0.7798\n",
      "Epoch 49: val_accuracy improved from 0.80475 to 0.81350, saving model to D:/testing_1_cvt/Model_CVT_prueba1_04S-UNIWARD_1729515488.1369982\\saved-model.hdf5\n",
      "1500/1500 [==============================] - 750s 500ms/step - loss: 0.5712 - accuracy: 0.7798 - val_loss: 0.5863 - val_accuracy: 0.8135\n",
      "Epoch 50/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.5653 - accuracy: 0.7857\n",
      "Epoch 50: val_accuracy did not improve from 0.81350\n",
      "1500/1500 [==============================] - 747s 498ms/step - loss: 0.5653 - accuracy: 0.7857 - val_loss: 0.5616 - val_accuracy: 0.8117\n",
      "Epoch 51/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.5599 - accuracy: 0.7877\n",
      "Epoch 51: val_accuracy improved from 0.81350 to 0.81575, saving model to D:/testing_1_cvt/Model_CVT_prueba1_04S-UNIWARD_1729515488.1369982\\saved-model.hdf5\n",
      "1500/1500 [==============================] - 755s 504ms/step - loss: 0.5599 - accuracy: 0.7877 - val_loss: 0.6071 - val_accuracy: 0.8158\n",
      "Epoch 52/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.5548 - accuracy: 0.7947\n",
      "Epoch 52: val_accuracy did not improve from 0.81575\n",
      "1500/1500 [==============================] - 752s 501ms/step - loss: 0.5548 - accuracy: 0.7947 - val_loss: 0.6255 - val_accuracy: 0.8045\n",
      "Epoch 53/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.5467 - accuracy: 0.7912\n",
      "Epoch 53: val_accuracy did not improve from 0.81575\n",
      "1500/1500 [==============================] - 751s 501ms/step - loss: 0.5467 - accuracy: 0.7912 - val_loss: 0.6471 - val_accuracy: 0.7993\n",
      "Epoch 54/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.5438 - accuracy: 0.7937\n",
      "Epoch 54: val_accuracy improved from 0.81575 to 0.82775, saving model to D:/testing_1_cvt/Model_CVT_prueba1_04S-UNIWARD_1729515488.1369982\\saved-model.hdf5\n",
      "1500/1500 [==============================] - 751s 500ms/step - loss: 0.5438 - accuracy: 0.7937 - val_loss: 0.5188 - val_accuracy: 0.8278\n",
      "Epoch 55/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.5362 - accuracy: 0.8020\n",
      "Epoch 55: val_accuracy did not improve from 0.82775\n",
      "1500/1500 [==============================] - 756s 504ms/step - loss: 0.5362 - accuracy: 0.8020 - val_loss: 0.5787 - val_accuracy: 0.7990\n",
      "Epoch 56/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.5328 - accuracy: 0.8008\n",
      "Epoch 56: val_accuracy improved from 0.82775 to 0.83275, saving model to D:/testing_1_cvt/Model_CVT_prueba1_04S-UNIWARD_1729515488.1369982\\saved-model.hdf5\n",
      "1500/1500 [==============================] - 764s 510ms/step - loss: 0.5328 - accuracy: 0.8008 - val_loss: 0.5255 - val_accuracy: 0.8328\n",
      "Epoch 57/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.5289 - accuracy: 0.8030\n",
      "Epoch 57: val_accuracy did not improve from 0.83275\n",
      "1500/1500 [==============================] - 755s 503ms/step - loss: 0.5289 - accuracy: 0.8030 - val_loss: 0.8143 - val_accuracy: 0.7295\n",
      "Epoch 58/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.5258 - accuracy: 0.8020\n",
      "Epoch 58: val_accuracy did not improve from 0.83275\n",
      "1500/1500 [==============================] - 752s 502ms/step - loss: 0.5258 - accuracy: 0.8020 - val_loss: 0.5573 - val_accuracy: 0.8130\n",
      "Epoch 59/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.5094 - accuracy: 0.8117\n",
      "Epoch 59: val_accuracy did not improve from 0.83275\n",
      "1500/1500 [==============================] - 755s 504ms/step - loss: 0.5094 - accuracy: 0.8117 - val_loss: 0.5561 - val_accuracy: 0.8285\n",
      "Epoch 60/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.5074 - accuracy: 0.8148\n",
      "Epoch 60: val_accuracy did not improve from 0.83275\n",
      "1500/1500 [==============================] - 757s 504ms/step - loss: 0.5074 - accuracy: 0.8148 - val_loss: 0.5645 - val_accuracy: 0.8207\n",
      "Epoch 61/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.5084 - accuracy: 0.8123\n",
      "Epoch 61: val_accuracy did not improve from 0.83275\n",
      "1500/1500 [==============================] - 757s 505ms/step - loss: 0.5084 - accuracy: 0.8123 - val_loss: 0.5686 - val_accuracy: 0.8310\n",
      "Epoch 62/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.5032 - accuracy: 0.8158\n",
      "Epoch 62: val_accuracy improved from 0.83275 to 0.83525, saving model to D:/testing_1_cvt/Model_CVT_prueba1_04S-UNIWARD_1729515488.1369982\\saved-model.hdf5\n",
      "1500/1500 [==============================] - 756s 504ms/step - loss: 0.5032 - accuracy: 0.8158 - val_loss: 0.5154 - val_accuracy: 0.8353\n",
      "Epoch 63/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4987 - accuracy: 0.8191\n",
      "Epoch 63: val_accuracy improved from 0.83525 to 0.83625, saving model to D:/testing_1_cvt/Model_CVT_prueba1_04S-UNIWARD_1729515488.1369982\\saved-model.hdf5\n",
      "1500/1500 [==============================] - 748s 499ms/step - loss: 0.4987 - accuracy: 0.8191 - val_loss: 0.5229 - val_accuracy: 0.8363\n",
      "Epoch 64/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4944 - accuracy: 0.8187\n",
      "Epoch 64: val_accuracy did not improve from 0.83625\n",
      "1500/1500 [==============================] - 759s 506ms/step - loss: 0.4944 - accuracy: 0.8187 - val_loss: 0.5820 - val_accuracy: 0.8225\n",
      "Epoch 65/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.5020 - accuracy: 0.8172\n",
      "Epoch 65: val_accuracy did not improve from 0.83625\n",
      "1500/1500 [==============================] - 748s 499ms/step - loss: 0.5020 - accuracy: 0.8172 - val_loss: 0.5226 - val_accuracy: 0.8292\n",
      "Epoch 66/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4869 - accuracy: 0.8224\n",
      "Epoch 66: val_accuracy did not improve from 0.83625\n",
      "1500/1500 [==============================] - 751s 501ms/step - loss: 0.4869 - accuracy: 0.8224 - val_loss: 0.5649 - val_accuracy: 0.8288\n",
      "Epoch 67/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4812 - accuracy: 0.8263\n",
      "Epoch 67: val_accuracy did not improve from 0.83625\n",
      "1500/1500 [==============================] - 751s 501ms/step - loss: 0.4812 - accuracy: 0.8263 - val_loss: 0.6090 - val_accuracy: 0.8347\n",
      "Epoch 68/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4669 - accuracy: 0.8332\n",
      "Epoch 68: val_accuracy improved from 0.83625 to 0.84500, saving model to D:/testing_1_cvt/Model_CVT_prueba1_04S-UNIWARD_1729515488.1369982\\saved-model.hdf5\n",
      "1500/1500 [==============================] - 753s 502ms/step - loss: 0.4669 - accuracy: 0.8332 - val_loss: 0.5678 - val_accuracy: 0.8450\n",
      "Epoch 69/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4710 - accuracy: 0.8332\n",
      "Epoch 69: val_accuracy did not improve from 0.84500\n",
      "1500/1500 [==============================] - 754s 503ms/step - loss: 0.4710 - accuracy: 0.8332 - val_loss: 0.6529 - val_accuracy: 0.8320\n",
      "Epoch 70/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4743 - accuracy: 0.8287\n",
      "Epoch 70: val_accuracy did not improve from 0.84500\n",
      "1500/1500 [==============================] - 755s 503ms/step - loss: 0.4743 - accuracy: 0.8287 - val_loss: 0.5901 - val_accuracy: 0.8278\n",
      "Epoch 71/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4680 - accuracy: 0.8367\n",
      "Epoch 71: val_accuracy did not improve from 0.84500\n",
      "1500/1500 [==============================] - 764s 509ms/step - loss: 0.4680 - accuracy: 0.8367 - val_loss: 0.6101 - val_accuracy: 0.8305\n",
      "Epoch 72/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4642 - accuracy: 0.8321\n",
      "Epoch 72: val_accuracy did not improve from 0.84500\n",
      "1500/1500 [==============================] - 755s 504ms/step - loss: 0.4642 - accuracy: 0.8321 - val_loss: 0.6540 - val_accuracy: 0.8303\n",
      "Epoch 73/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4612 - accuracy: 0.8368\n",
      "Epoch 73: val_accuracy did not improve from 0.84500\n",
      "1500/1500 [==============================] - 745s 497ms/step - loss: 0.4612 - accuracy: 0.8368 - val_loss: 0.5910 - val_accuracy: 0.8205\n",
      "Epoch 74/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4573 - accuracy: 0.8391\n",
      "Epoch 74: val_accuracy did not improve from 0.84500\n",
      "1500/1500 [==============================] - 746s 498ms/step - loss: 0.4573 - accuracy: 0.8391 - val_loss: 0.5450 - val_accuracy: 0.8440\n",
      "Epoch 75/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4531 - accuracy: 0.8424\n",
      "Epoch 75: val_accuracy did not improve from 0.84500\n",
      "1500/1500 [==============================] - 748s 498ms/step - loss: 0.4531 - accuracy: 0.8424 - val_loss: 0.6260 - val_accuracy: 0.8257\n",
      "Epoch 76/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4508 - accuracy: 0.8398\n",
      "Epoch 76: val_accuracy did not improve from 0.84500\n",
      "1500/1500 [==============================] - 749s 499ms/step - loss: 0.4508 - accuracy: 0.8398 - val_loss: 0.6273 - val_accuracy: 0.8303\n",
      "Epoch 77/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4451 - accuracy: 0.8427\n",
      "Epoch 77: val_accuracy did not improve from 0.84500\n",
      "1500/1500 [==============================] - 749s 499ms/step - loss: 0.4451 - accuracy: 0.8427 - val_loss: 0.5127 - val_accuracy: 0.8422\n",
      "Epoch 78/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4410 - accuracy: 0.8450\n",
      "Epoch 78: val_accuracy did not improve from 0.84500\n",
      "1500/1500 [==============================] - 751s 501ms/step - loss: 0.4410 - accuracy: 0.8450 - val_loss: 0.5476 - val_accuracy: 0.8397\n",
      "Epoch 79/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4475 - accuracy: 0.8404\n",
      "Epoch 79: val_accuracy did not improve from 0.84500\n",
      "1500/1500 [==============================] - 751s 501ms/step - loss: 0.4475 - accuracy: 0.8404 - val_loss: 0.5336 - val_accuracy: 0.8235\n",
      "Epoch 80/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4302 - accuracy: 0.8497\n",
      "Epoch 80: val_accuracy improved from 0.84500 to 0.84675, saving model to D:/testing_1_cvt/Model_CVT_prueba1_04S-UNIWARD_1729515488.1369982\\saved-model.hdf5\n",
      "1500/1500 [==============================] - 753s 502ms/step - loss: 0.4302 - accuracy: 0.8497 - val_loss: 0.5888 - val_accuracy: 0.8468\n",
      "Epoch 81/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4434 - accuracy: 0.8421\n",
      "Epoch 81: val_accuracy did not improve from 0.84675\n",
      "1500/1500 [==============================] - 765s 510ms/step - loss: 0.4434 - accuracy: 0.8421 - val_loss: 0.5270 - val_accuracy: 0.8393\n",
      "Epoch 82/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4263 - accuracy: 0.8561\n",
      "Epoch 82: val_accuracy did not improve from 0.84675\n",
      "1500/1500 [==============================] - 753s 502ms/step - loss: 0.4263 - accuracy: 0.8561 - val_loss: 0.9185 - val_accuracy: 0.7782\n",
      "Epoch 83/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4281 - accuracy: 0.8515\n",
      "Epoch 83: val_accuracy did not improve from 0.84675\n",
      "1500/1500 [==============================] - 750s 500ms/step - loss: 0.4281 - accuracy: 0.8515 - val_loss: 0.5874 - val_accuracy: 0.8462\n",
      "Epoch 84/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4223 - accuracy: 0.8523\n",
      "Epoch 84: val_accuracy improved from 0.84675 to 0.85350, saving model to D:/testing_1_cvt/Model_CVT_prueba1_04S-UNIWARD_1729515488.1369982\\saved-model.hdf5\n",
      "1500/1500 [==============================] - 749s 499ms/step - loss: 0.4223 - accuracy: 0.8523 - val_loss: 0.4755 - val_accuracy: 0.8535\n",
      "Epoch 85/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4235 - accuracy: 0.8564\n",
      "Epoch 85: val_accuracy did not improve from 0.85350\n",
      "1500/1500 [==============================] - 748s 499ms/step - loss: 0.4235 - accuracy: 0.8564 - val_loss: 0.4876 - val_accuracy: 0.8505\n",
      "Epoch 86/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4162 - accuracy: 0.8580\n",
      "Epoch 86: val_accuracy did not improve from 0.85350\n",
      "1500/1500 [==============================] - 748s 499ms/step - loss: 0.4162 - accuracy: 0.8580 - val_loss: 0.5609 - val_accuracy: 0.8347\n",
      "Epoch 87/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4246 - accuracy: 0.8520\n",
      "Epoch 87: val_accuracy did not improve from 0.85350\n",
      "1500/1500 [==============================] - 751s 501ms/step - loss: 0.4246 - accuracy: 0.8520 - val_loss: 0.5541 - val_accuracy: 0.8510\n",
      "Epoch 88/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4128 - accuracy: 0.8623\n",
      "Epoch 88: val_accuracy did not improve from 0.85350\n",
      "1500/1500 [==============================] - 751s 501ms/step - loss: 0.4128 - accuracy: 0.8623 - val_loss: 0.5537 - val_accuracy: 0.8432\n",
      "Epoch 89/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4173 - accuracy: 0.8581\n",
      "Epoch 89: val_accuracy did not improve from 0.85350\n",
      "1500/1500 [==============================] - 765s 510ms/step - loss: 0.4173 - accuracy: 0.8581 - val_loss: 0.4995 - val_accuracy: 0.8447\n",
      "Epoch 90/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4080 - accuracy: 0.8601\n",
      "Epoch 90: val_accuracy improved from 0.85350 to 0.85500, saving model to D:/testing_1_cvt/Model_CVT_prueba1_04S-UNIWARD_1729515488.1369982\\saved-model.hdf5\n",
      "1500/1500 [==============================] - 755s 503ms/step - loss: 0.4080 - accuracy: 0.8601 - val_loss: 0.5557 - val_accuracy: 0.8550\n",
      "Epoch 91/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4084 - accuracy: 0.8617\n",
      "Epoch 91: val_accuracy did not improve from 0.85500\n",
      "1500/1500 [==============================] - 754s 503ms/step - loss: 0.4084 - accuracy: 0.8617 - val_loss: 0.5751 - val_accuracy: 0.8375\n",
      "Epoch 92/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4101 - accuracy: 0.8612\n",
      "Epoch 92: val_accuracy did not improve from 0.85500\n",
      "1500/1500 [==============================] - 754s 503ms/step - loss: 0.4101 - accuracy: 0.8612 - val_loss: 0.4743 - val_accuracy: 0.8543\n",
      "Epoch 93/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4023 - accuracy: 0.8608\n",
      "Epoch 93: val_accuracy did not improve from 0.85500\n",
      "1500/1500 [==============================] - 751s 501ms/step - loss: 0.4023 - accuracy: 0.8608 - val_loss: 0.6251 - val_accuracy: 0.8422\n",
      "Epoch 94/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4021 - accuracy: 0.8645\n",
      "Epoch 94: val_accuracy did not improve from 0.85500\n",
      "1500/1500 [==============================] - 749s 499ms/step - loss: 0.4021 - accuracy: 0.8645 - val_loss: 0.6131 - val_accuracy: 0.8435\n",
      "Epoch 95/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.4003 - accuracy: 0.8664\n",
      "Epoch 95: val_accuracy did not improve from 0.85500\n",
      "1500/1500 [==============================] - 749s 499ms/step - loss: 0.4003 - accuracy: 0.8664 - val_loss: 0.5612 - val_accuracy: 0.8545\n",
      "Epoch 96/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3941 - accuracy: 0.8668\n",
      "Epoch 96: val_accuracy did not improve from 0.85500\n",
      "1500/1500 [==============================] - 746s 498ms/step - loss: 0.3941 - accuracy: 0.8668 - val_loss: 0.8340 - val_accuracy: 0.8008\n",
      "Epoch 97/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3985 - accuracy: 0.8677\n",
      "Epoch 97: val_accuracy did not improve from 0.85500\n",
      "1500/1500 [==============================] - 764s 509ms/step - loss: 0.3985 - accuracy: 0.8677 - val_loss: 0.4928 - val_accuracy: 0.8533\n",
      "Epoch 98/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3914 - accuracy: 0.8688\n",
      "Epoch 98: val_accuracy improved from 0.85500 to 0.85650, saving model to D:/testing_1_cvt/Model_CVT_prueba1_04S-UNIWARD_1729515488.1369982\\saved-model.hdf5\n",
      "1500/1500 [==============================] - 753s 502ms/step - loss: 0.3914 - accuracy: 0.8688 - val_loss: 0.5252 - val_accuracy: 0.8565\n",
      "Epoch 99/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3973 - accuracy: 0.8697\n",
      "Epoch 99: val_accuracy did not improve from 0.85650\n",
      "1500/1500 [==============================] - 754s 502ms/step - loss: 0.3973 - accuracy: 0.8697 - val_loss: 0.5896 - val_accuracy: 0.8520\n",
      "Epoch 100/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3855 - accuracy: 0.8723\n",
      "Epoch 100: val_accuracy did not improve from 0.85650\n",
      "1500/1500 [==============================] - 754s 503ms/step - loss: 0.3855 - accuracy: 0.8723 - val_loss: 0.6307 - val_accuracy: 0.8345\n",
      "Epoch 101/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3894 - accuracy: 0.8710\n",
      "Epoch 101: val_accuracy did not improve from 0.85650\n",
      "1500/1500 [==============================] - 754s 503ms/step - loss: 0.3894 - accuracy: 0.8710 - val_loss: 0.6345 - val_accuracy: 0.8320\n",
      "Epoch 102/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3891 - accuracy: 0.8684\n",
      "Epoch 102: val_accuracy did not improve from 0.85650\n",
      "1500/1500 [==============================] - 754s 502ms/step - loss: 0.3891 - accuracy: 0.8684 - val_loss: 0.7340 - val_accuracy: 0.8288\n",
      "Epoch 103/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3830 - accuracy: 0.8738\n",
      "Epoch 103: val_accuracy improved from 0.85650 to 0.86275, saving model to D:/testing_1_cvt/Model_CVT_prueba1_04S-UNIWARD_1729515488.1369982\\saved-model.hdf5\n",
      "1500/1500 [==============================] - 753s 502ms/step - loss: 0.3830 - accuracy: 0.8738 - val_loss: 0.5133 - val_accuracy: 0.8627\n",
      "Epoch 104/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3823 - accuracy: 0.8748\n",
      "Epoch 104: val_accuracy did not improve from 0.86275\n",
      "1500/1500 [==============================] - 748s 499ms/step - loss: 0.3823 - accuracy: 0.8748 - val_loss: 0.5505 - val_accuracy: 0.8535\n",
      "Epoch 105/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3718 - accuracy: 0.8796\n",
      "Epoch 105: val_accuracy did not improve from 0.86275\n",
      "1500/1500 [==============================] - 749s 499ms/step - loss: 0.3718 - accuracy: 0.8796 - val_loss: 0.5561 - val_accuracy: 0.8515\n",
      "Epoch 106/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3762 - accuracy: 0.8758\n",
      "Epoch 106: val_accuracy did not improve from 0.86275\n",
      "1500/1500 [==============================] - 759s 506ms/step - loss: 0.3762 - accuracy: 0.8758 - val_loss: 0.6139 - val_accuracy: 0.8485\n",
      "Epoch 107/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3737 - accuracy: 0.8766\n",
      "Epoch 107: val_accuracy did not improve from 0.86275\n",
      "1500/1500 [==============================] - 753s 502ms/step - loss: 0.3737 - accuracy: 0.8766 - val_loss: 0.6620 - val_accuracy: 0.8393\n",
      "Epoch 108/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3779 - accuracy: 0.8739\n",
      "Epoch 108: val_accuracy did not improve from 0.86275\n",
      "1500/1500 [==============================] - 753s 502ms/step - loss: 0.3779 - accuracy: 0.8739 - val_loss: 0.4906 - val_accuracy: 0.8610\n",
      "Epoch 109/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3731 - accuracy: 0.8783\n",
      "Epoch 109: val_accuracy improved from 0.86275 to 0.86575, saving model to D:/testing_1_cvt/Model_CVT_prueba1_04S-UNIWARD_1729515488.1369982\\saved-model.hdf5\n",
      "1500/1500 [==============================] - 754s 503ms/step - loss: 0.3731 - accuracy: 0.8783 - val_loss: 0.5566 - val_accuracy: 0.8658\n",
      "Epoch 110/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3759 - accuracy: 0.8743\n",
      "Epoch 110: val_accuracy did not improve from 0.86575\n",
      "1500/1500 [==============================] - 753s 502ms/step - loss: 0.3759 - accuracy: 0.8743 - val_loss: 0.5314 - val_accuracy: 0.8643\n",
      "Epoch 111/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3678 - accuracy: 0.8813\n",
      "Epoch 111: val_accuracy did not improve from 0.86575\n",
      "1500/1500 [==============================] - 754s 503ms/step - loss: 0.3678 - accuracy: 0.8813 - val_loss: 0.8752 - val_accuracy: 0.7822\n",
      "Epoch 112/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3703 - accuracy: 0.8753\n",
      "Epoch 112: val_accuracy did not improve from 0.86575\n",
      "1500/1500 [==============================] - 754s 503ms/step - loss: 0.3703 - accuracy: 0.8753 - val_loss: 0.5261 - val_accuracy: 0.8533\n",
      "Epoch 113/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3528 - accuracy: 0.8864\n",
      "Epoch 113: val_accuracy did not improve from 0.86575\n",
      "1500/1500 [==============================] - 754s 503ms/step - loss: 0.3528 - accuracy: 0.8864 - val_loss: 0.6082 - val_accuracy: 0.8540\n",
      "Epoch 114/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3689 - accuracy: 0.8746\n",
      "Epoch 114: val_accuracy did not improve from 0.86575\n",
      "1500/1500 [==============================] - 760s 507ms/step - loss: 0.3689 - accuracy: 0.8746 - val_loss: 0.7334 - val_accuracy: 0.8328\n",
      "Epoch 115/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3636 - accuracy: 0.8814\n",
      "Epoch 115: val_accuracy did not improve from 0.86575\n",
      "1500/1500 [==============================] - 751s 501ms/step - loss: 0.3636 - accuracy: 0.8814 - val_loss: 0.5768 - val_accuracy: 0.8565\n",
      "Epoch 116/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3662 - accuracy: 0.8788\n",
      "Epoch 116: val_accuracy did not improve from 0.86575\n",
      "1500/1500 [==============================] - 750s 500ms/step - loss: 0.3662 - accuracy: 0.8788 - val_loss: 0.5324 - val_accuracy: 0.8472\n",
      "Epoch 117/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3598 - accuracy: 0.8817\n",
      "Epoch 117: val_accuracy did not improve from 0.86575\n",
      "1500/1500 [==============================] - 753s 502ms/step - loss: 0.3598 - accuracy: 0.8817 - val_loss: 0.5813 - val_accuracy: 0.8397\n",
      "Epoch 118/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3602 - accuracy: 0.8800\n",
      "Epoch 118: val_accuracy did not improve from 0.86575\n",
      "1500/1500 [==============================] - 754s 503ms/step - loss: 0.3602 - accuracy: 0.8800 - val_loss: 0.5183 - val_accuracy: 0.8500\n",
      "Epoch 119/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3566 - accuracy: 0.8844\n",
      "Epoch 119: val_accuracy did not improve from 0.86575\n",
      "1500/1500 [==============================] - 755s 503ms/step - loss: 0.3566 - accuracy: 0.8844 - val_loss: 0.7469 - val_accuracy: 0.8332\n",
      "Epoch 120/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3539 - accuracy: 0.8857\n",
      "Epoch 120: val_accuracy improved from 0.86575 to 0.86625, saving model to D:/testing_1_cvt/Model_CVT_prueba1_04S-UNIWARD_1729515488.1369982\\saved-model.hdf5\n",
      "1500/1500 [==============================] - 755s 504ms/step - loss: 0.3539 - accuracy: 0.8857 - val_loss: 0.5423 - val_accuracy: 0.8662\n",
      "Epoch 121/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3535 - accuracy: 0.8834\n",
      "Epoch 121: val_accuracy did not improve from 0.86625\n",
      "1500/1500 [==============================] - 756s 504ms/step - loss: 0.3535 - accuracy: 0.8834 - val_loss: 0.5976 - val_accuracy: 0.8528\n",
      "Epoch 122/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3464 - accuracy: 0.8915\n",
      "Epoch 122: val_accuracy did not improve from 0.86625\n",
      "1500/1500 [==============================] - 756s 504ms/step - loss: 0.3464 - accuracy: 0.8915 - val_loss: 0.5434 - val_accuracy: 0.8572\n",
      "Epoch 123/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3461 - accuracy: 0.8877\n",
      "Epoch 123: val_accuracy did not improve from 0.86625\n",
      "1500/1500 [==============================] - 768s 512ms/step - loss: 0.3461 - accuracy: 0.8877 - val_loss: 0.5654 - val_accuracy: 0.8597\n",
      "Epoch 124/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3558 - accuracy: 0.8827\n",
      "Epoch 124: val_accuracy did not improve from 0.86625\n",
      "1500/1500 [==============================] - 749s 499ms/step - loss: 0.3558 - accuracy: 0.8827 - val_loss: 0.6053 - val_accuracy: 0.8450\n",
      "Epoch 125/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3508 - accuracy: 0.8877\n",
      "Epoch 125: val_accuracy did not improve from 0.86625\n",
      "1500/1500 [==============================] - 746s 498ms/step - loss: 0.3508 - accuracy: 0.8877 - val_loss: 0.5532 - val_accuracy: 0.8500\n",
      "Epoch 126/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3446 - accuracy: 0.8898\n",
      "Epoch 126: val_accuracy did not improve from 0.86625\n",
      "1500/1500 [==============================] - 748s 499ms/step - loss: 0.3446 - accuracy: 0.8898 - val_loss: 0.4910 - val_accuracy: 0.8637\n",
      "Epoch 127/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3400 - accuracy: 0.8921\n",
      "Epoch 127: val_accuracy did not improve from 0.86625\n",
      "1500/1500 [==============================] - 752s 501ms/step - loss: 0.3400 - accuracy: 0.8921 - val_loss: 0.5339 - val_accuracy: 0.8633\n",
      "Epoch 128/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3409 - accuracy: 0.8902\n",
      "Epoch 128: val_accuracy did not improve from 0.86625\n",
      "1500/1500 [==============================] - 753s 502ms/step - loss: 0.3409 - accuracy: 0.8902 - val_loss: 0.5272 - val_accuracy: 0.8635\n",
      "Epoch 129/800\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3441 - accuracy: 0.8913\n",
      "Epoch 129: val_accuracy did not improve from 0.86625\n",
      "1500/1500 [==============================] - 759s 506ms/step - loss: 0.3441 - accuracy: 0.8913 - val_loss: 0.5396 - val_accuracy: 0.8595\n",
      "Epoch 130/800\n",
      " 974/1500 [==================>...........] - ETA: 4:10 - loss: 0.3453 - accuracy: 0.8907"
     ]
    }
   ],
   "source": [
    "base_name=\"04S-UNIWARD\"\n",
    "name=\"Model_\"+'CAPSNET_prueba1'+\"_\"+base_name\n",
    "_, history  = train(model, X_train, y_train, X_valid, y_valid, X_test, y_test, batch_size=8, epochs=800, model_name=name, num_test='1_capsnet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
